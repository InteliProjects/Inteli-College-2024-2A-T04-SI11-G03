{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUhHmPliWe4I"
   },
   "source": [
    "# Importação das Bibliotecas que serão utilizadas no Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuPRD6dbGSOd",
    "outputId": "37b53f1d-a1c7-47fc-94b0-41efa8e933cd"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7dzFab-JL9Z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpHUfSncWpaO"
   },
   "source": [
    "## Download dos arquivos contendo os datasets de consumo desde 2019 a 2024\n",
    "  - Aqui retiramos a base de 2020, por conta da pandemia do Coronavírus. Foi uma escolha do grupo devido à possibilidade de discrepância nas leituras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EG9a2W-kzQXc",
    "outputId": "3469b88a-0664-40f7-de1e-0594f09fce8a"
   },
   "outputs": [],
   "source": [
    "arquivo_destino_base = \"dataset_{}.csv\"\n",
    "\n",
    "ids = {\n",
    "    \"consumo_2024\": \"1-iXT7eaJWQokHf9cyfrB8N5wvkdhgjJW\",\n",
    "    \"consumo_2023\": \"1-WfvkRwaRr85B_Joxcm9xVdpyg5NBAmp\",\n",
    "    \"consumo_2022\": \"1-Uu4Tf4lufJVFeJnYKc5w7OeW66pe1eC\",\n",
    "    \"consumo_2021\": \"1-2PsTLzG4dcY4wM0p7vFfabUuLv950gC\",\n",
    "    \"consumo_2020\": \"1-1pOoa0eJlNJ94BMi7p4PTx5KUS96mhX\",\n",
    "    \"consumo_2019\": \"1-2PsTLzG4dcY4wM0p7vFfabUuLv950gC\",\n",
    "    \"CONSUMO_GERAL\": \"1-IOqfwmh_tTIDHeOer8J-HkGFtwuX67g\",\n",
    "}\n",
    "\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "\n",
    "for key, file_id in ids.items():\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    arquivo_destino = arquivo_destino_base.format(key)\n",
    "\n",
    "    gdown.download(url, arquivo_destino, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OFwaINKz9a2",
    "outputId": "fe39eea9-754b-4bcc-faf5-785032c9674c"
   },
   "outputs": [],
   "source": [
    "arquivos_csv = [\n",
    "    \"./dataset_consumo_2024.csv\",\n",
    "    \"./dataset_consumo_2023.csv\",\n",
    "    \"./dataset_consumo_2022.csv\",\n",
    "    \"./dataset_consumo_2021.csv\",\n",
    "    \"./dataset_consumo_2019.csv\",\n",
    "]\n",
    "\n",
    "ALL_COLUMNS_CONSUMO_GERAL = pd.concat([pd.read_csv(arquivo, delimiter=\";\") for arquivo in arquivos_csv], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkGPmDOtKmkN"
   },
   "outputs": [],
   "source": [
    "consumo_geral = pd.read_csv('/content/dataset_CONSUMO_GERAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7-Y6UF0XCuM"
   },
   "source": [
    "## Download do dataset com o Target das Fraudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULyqg7TpoDYI",
    "outputId": "94c3a9df-0754-43cf-b87e-894db7dbe32b"
   },
   "outputs": [],
   "source": [
    "file_id_fraudes = \"1-MbIlChqQapcxFkoJgpbQIsN9FBLfbX1\"\n",
    "url_fraudes = f\"https://drive.google.com/uc?id={file_id_fraudes}\"\n",
    "\n",
    "gdown.download(url_fraudes, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6w7_peSCn7Ug"
   },
   "outputs": [],
   "source": [
    "fraudes = pd.read_csv('/content/fraudes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldtmRy7UXLY3"
   },
   "source": [
    "### A tabela \"ALL_COLUMNS_CONSUMO_GERAL\" possui todas as tabelas de consumo e a partir disso decidimos considerar algumas colunas categóricas que podem ajudar a melhorar o desempenho do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UOb4m0J-5TCL",
    "outputId": "b9d47604-b670-4947-9fa5-0da6091d4598"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_EHJc8LXlev"
   },
   "source": [
    "### Remoção de colunas indesejadas até o momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC1ItnrL4iiS"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL = ALL_COLUMNS_CONSUMO_GERAL.drop(columns=['Unnamed: 0', 'EMP_CODIGO', 'COD_GRUPO', 'COD_SETOR_COMERCIAL', 'NUM_QUADRA', 'COD_ROTA_LEITURA', 'SEQ_RESPONSAVEL', 'ECO_RESIDENCIAL', 'ECO_COMERCIAL', 'ECO_INDUSTRIAL', 'ECO_PUBLICA', 'ECO_OUTRAS','LTR_ATUAL', 'LTR_COLETADA', 'DAT_LEITURA', 'DIAS_LEITURA', 'COD_LEITURA_INF_1', 'COD_LEITURA_INF_2', 'COD_LEITURA_INF_3', 'HORA_LEITURA', 'DSC_SIMULTANEA', 'COD_LEITURA_INT','EXCECAO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbkHY73-EKfq",
    "outputId": "92fa5aa5-5a4f-40a6-f76e-e4f63f3fde96"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noqyuFdPXq6m"
   },
   "source": [
    "### Nessa seção queriamos validar a tabela de \"VOLUME_ESTIMADO_ACUM\" para ver se ela poderia agregar dentro do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXw_shC3ETEC",
    "outputId": "2ed9f407-0d6a-472c-bb2b-2e8fb383add7"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL[['VOLUME_ESTIMADO_ACUM']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QQpwtHo1EQR1",
    "outputId": "c4fb1562-0eab-43ba-e3cb-feff1eb76fb5"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL[ALL_COLUMNS_CONSUMO_GERAL['VOLUME_ESTIMADO'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpDnM5voX7uN"
   },
   "source": [
    "#### O insight retirado aqui é que talvez a melhor coluna para validação e ser utilizada como featura no modelo é a coluna de Volume Estimado. Ela possui maior consistência nos resultados, do que a coluna de Volume Estimado Acumulado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSkEsnRrZxSk"
   },
   "source": [
    "### Separação de Features relevantes\n",
    "\n",
    "Após pesquisas e visualizar as colunas disponíveis, percebemos uma coluna que poderia ser interessante para o processo de identificação de fraude. A coluna de \"DSC_OCORRENCIA\". Ela basicamente corresponde a descrição de como foi o processo de vistoria e coleta do responsável e em cada um dos domicílios (matrícula)\n",
    "\n",
    "Isso surgiu como uma possibilidade de tentar direcionar o modelo para casos nos quais há uma maior possibilidade de uma fraude, de acordo com a visualização do medidor em cada um desses domicílios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XGr7R_w_Kei0",
    "outputId": "32ec8e7f-23aa-4246-d456-a564eea4d35a"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI = ALL_COLUMNS_CONSUMO_GERAL[ALL_COLUMNS_CONSUMO_GERAL['DSC_OCORRENCIA'].isin([\n",
    "    'NORMAL',\n",
    "    'MEDIDOR RETIRADO/FURTADO',\n",
    "    'LEITURA COLETADA PELO CLIENTE',\n",
    "    'MEDIDOR NÃO LOCALIZADO',\n",
    "    'IMÓVEL DESOCUPADO'\n",
    "])]\n",
    "\n",
    "ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h0_spJ_rGdD"
   },
   "source": [
    "## Tratando Dataframe com mais colunas targets adicionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEWOIr3RbEGS"
   },
   "source": [
    "#### Seperação do Dataframe apenas para a visualização das matriculas com Categoria Residencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "id_RoNM8ZUGh",
    "outputId": "021820d9-950c-4d02-fcec-73725b5d55ea"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI[ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI[\"CATEGORIA\"].isin([\"COMERCIAL\", \"PUBLICA\", \"INDUSTRIAL\"])]\n",
    "dataframe_pj_premissa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjuI7kQgbPQl"
   },
   "source": [
    "### Processo de One Hot Encoding para as Colunas, as quais serão as features para o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZlsXF8r0Ojo"
   },
   "outputs": [],
   "source": [
    "# Fazendo o one hot encoding \n",
    "\n",
    "dataframe_pj_premissa = pd.get_dummies(dataframe_pj_premissa, columns=['TIPO_LIGACAO', 'DSC_OCORRENCIA', 'STA_TROCA', 'STA_ACEITA_LEITURA'], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2J6lQ4lSR884",
    "outputId": "9e3aa1ff-c77d-40e8-dfb2-b7dd17b550b3"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratando os valores da tabela de fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nIyTxQ03lDv",
    "outputId": "ac73e124-423a-483a-b8c2-a550ff50e5e1"
   },
   "outputs": [],
   "source": [
    "# analizando as colunas\n",
    "\n",
    "fraudes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sqp4unc3MG-"
   },
   "outputs": [],
   "source": [
    "# removendo os duplicados do dataframe de fraudes\n",
    "dataframe_fraudes_premissa = fraudes[['MATRICULA', 'DESCRICAO']].drop_duplicates()\n",
    "\n",
    "# fazendo o one hot encoding do dataframe de fraudes\n",
    "dataframe_fraudes_premissa = pd.get_dummies(dataframe_fraudes_premissa, columns=['DESCRICAO'], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVlUTM94tGEY",
    "outputId": "aa84ba9a-514a-4812-c6c5-7e36973ebd23"
   },
   "outputs": [],
   "source": [
    "# analizando o tipo de dados que temos na tabela de fraudes\n",
    "\n",
    "dataframe_fraudes_premissa['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fMcRIGX4Tub"
   },
   "outputs": [],
   "source": [
    "# Realiza a junção (merge) entre 'dataframe_pj_premissa' e 'dataframe_fraudes_premissa' com base na coluna 'MATRICULA', \n",
    "# mantendo todas as linhas de 'dataframe_pj_premissa' e adicionando informações de 'dataframe_fraudes_premissa' quando disponíveis\n",
    "dataframe_pj_premissa = pd.merge(dataframe_pj_premissa, dataframe_fraudes_premissa, on='MATRICULA', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWa718hq5QpO",
    "outputId": "0b12743c-d91c-4cf9-a166-fc30f2450a92"
   },
   "outputs": [],
   "source": [
    "# dataframe_pj_premissa.drop_duplicates(subset=\"MATRICULA\", keep='first')\n",
    "dataframe_pj_premissa.dropna(subset=\"REFERENCIA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKk7toKYflb8"
   },
   "source": [
    "### Normalizando com o Robust Scaler\n",
    "\n",
    "O RobustScaler é uma técnica de normalização usada para transformar dados. Ele é útil especialmente quando os dados contêm outliers, ou seja, valores atípicos que podem distorcer (neste caso o Consumo e o Volume) os resultados de outras técnicas de escalonamento, como StandardScaler ou MinMaxScaler.\n",
    "\n",
    "O RobustScaler transforma os dados subtraindo a mediana e dividindo pela amplitude interquartil (IQR, Interquartile Range). A mediana é o valor do ponto médio quando os dados são ordenados, e o IQR é a diferença entre o terceiro quartil (75º percentil) e o primeiro quartil (25º percentil).\n",
    "\n",
    "Esse método é menos sensível a outliers porque, ao contrário da média e do desvio padrão (usados pelo StandardScaler), a mediana e o IQR não são afetados por valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sizbtxDrUkvL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "\n",
    "# exercendo a normalização\n",
    "dataframe_pj_premissa[['CONS_MEDIDO']] = scaler.fit_transform(dataframe_pj_premissa[['CONS_MEDIDO']])\n",
    "dataframe_pj_premissa[['VOLUME_ESTIMADO']] = scaler.fit_transform(dataframe_pj_premissa[['VOLUME_ESTIMADO']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivotando a tabela de consumo\n",
    "\n",
    "- Para o index ficar na matrícula e ter uma representação das datas temporais em formato de colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gb041Z7n7zUf",
    "outputId": "139afe9f-6081-4f55-a778-957c6e499513"
   },
   "outputs": [],
   "source": [
    "# Cria uma tabela dinâmica (pivot table) a partir de 'dataframe_pj_premissa', usando 'MATRICULA' como índice,\n",
    "# 'REFERENCIA' como colunas, e somando os valores de 'CONS_MEDIDO' e 'VOLUME_ESTIMADO'\n",
    "pivoted_df = pd.pivot_table(\n",
    "    dataframe_pj_premissa,\n",
    "    index='MATRICULA',\n",
    "    columns='REFERENCIA',\n",
    "    values=['CONS_MEDIDO', 'VOLUME_ESTIMADO'],\n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "# Concatena os nomes das colunas resultantes, unindo os nomes com um underline ('_') e removendo espaços extras\n",
    "pivoted_df.columns = ['_'.join(col).strip() for col in pivoted_df.columns.values]\n",
    "\n",
    "# Reseta o índice para que 'MATRICULA' volte a ser uma coluna regular\n",
    "pivoted_df = pivoted_df.reset_index()\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame resultante\n",
    "pivoted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh6Wog6Wv2ks",
    "outputId": "30fff6ef-420f-4412-b55d-e3fff6a2b18f"
   },
   "outputs": [],
   "source": [
    "# analizando resultados\n",
    "\n",
    "len(pivoted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzm0etx4f39Y"
   },
   "source": [
    "### Atribuição de cada uma das variáveis categóricas ao dataframe com o consumo e volume históricos\n",
    "\n",
    "- O código integra dados de tipo de ligação, ocorrências de medidores e identificação de irregularidades ao DataFrame principal, pivoted_df. Após cada junção, os valores nulos são substituídos por zero para garantir a completude dos dados. \n",
    "\n",
    "- É importante citar aqui que atribuímos a premissa que a primeira definição de tipo de ligação, descrição e os outros utilizados, serão os que tomaremos como base para inferência dentro do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEg8bcZ8AWmA"
   },
   "outputs": [],
   "source": [
    "# fazendo o tratamento e a junção da coluna de tipo de ligação\n",
    "\n",
    "tipo_ligacao = dataframe_pj_premissa[['MATRICULA','TIPO_LIGACAO_Consumo Fixo', 'TIPO_LIGACAO_Hidrometrado']].drop_duplicates(subset='MATRICULA', keep='first')\n",
    "pivoted_df = pivoted_df.merge(tipo_ligacao, on='MATRICULA', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2Aj6H_iBS6h"
   },
   "outputs": [],
   "source": [
    "# fazendo o tratamento e a junção do tipo de ocorrencia\n",
    "\n",
    "descricao_ocorrencia = dataframe_pj_premissa[['MATRICULA','DSC_OCORRENCIA_MEDIDOR NÃO LOCALIZADO', 'DSC_OCORRENCIA_MEDIDOR RETIRADO/FURTADO', 'DSC_OCORRENCIA_NORMAL']].drop_duplicates(subset='MATRICULA', keep='first')\n",
    "pivoted_df = pivoted_df.merge(descricao_ocorrencia, on='MATRICULA', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faW98EliCUo6"
   },
   "outputs": [],
   "source": [
    "# juntando a tabela de consumo com a de fraude. Preenchendo os valores vazios (as que não estão na tabela de fraude) com zero, representando que eles não cometeram fraude\n",
    "\n",
    "fraude_ou_não = dataframe_pj_premissa[['MATRICULA','DESCRICAO_IRREGULARIDADE IDENTIFICADA']].drop_duplicates(subset='MATRICULA', keep='first')\n",
    "pivoted_df = pivoted_df.merge(fraude_ou_não, on='MATRICULA', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df = pivoted_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0U6g1CIhDdtA",
    "outputId": "2a768f71-12d1-4568-9d27-fc6d004dc63a"
   },
   "outputs": [],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57gpeUyH-Bjx"
   },
   "source": [
    "## Rodando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJ21gZSXzNg"
   },
   "source": [
    "### Divisão de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAiaqzOm9hSY",
    "outputId": "a8de1329-efc9-4b06-d754-7c333a602462"
   },
   "outputs": [],
   "source": [
    "pivoted_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPeNvcbLgh1h"
   },
   "source": [
    "#### Balanceando os dados com Smote (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "O smote é uma técnica de \"oversampling\" usada para balancear datasets com o objetivo de aumentar a quantidade de amostras da classe minoritária gerando novos exemplos sintéticos, em vez de simplesmente replicar os dados existentes. Isso ajuda a melhorar a performance de modelos de machine learning ao treinar com um dataset mais balanceado.\n",
    "\n",
    "Quando você treina um modelo de machine learning com um dataset desbalanceado (onde uma classe tem muito mais exemplos do que a outra), o modelo tende a favorecer a classe majoritária.\n",
    "\n",
    "Como resultado, o modelo pode ter um bom desempenho em termos de acurácia geral, mas um desempenho ruim ao identificar a classe minoritária (por exemplo, falhas, fraudes, etc.).\n",
    "\n",
    "O Smote ajuda a mitigar esse problema ao balancear o dataset, aumentando o número de exemplos da classe minoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efy-miOag6Jq"
   },
   "outputs": [],
   "source": [
    "# função para balanciar\n",
    "\n",
    "def balanciar(df):\n",
    "  smote = SMOTE(random_state=42)\n",
    "  X = pivoted_df.drop('DESCRICAO_IRREGULARIDADE IDENTIFICADA', axis=1)\n",
    "  y = pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA']\n",
    "  X_res, y_res = smote.fit_resample(X, y)\n",
    "  return pd.concat([X_res, y_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7rhSEoIxijy",
    "outputId": "80a66afb-2ecb-44ba-b2e1-946e435d3588"
   },
   "outputs": [],
   "source": [
    "# analizando a distribuição do label nos dados antes do balanciamento\n",
    "\n",
    "np.unique(pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanciando os dodos\n",
    "\n",
    "pivoted_df = balanciar(pivoted_df.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN4ph0X3zJGc"
   },
   "outputs": [],
   "source": [
    "# dividindo label e dados para previsão\n",
    "\n",
    "y = pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].values\n",
    "X = pivoted_df.drop(['MATRICULA','DESCRICAO_IRREGULARIDADE IDENTIFICADA'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSYszgHggtMX"
   },
   "outputs": [],
   "source": [
    "# dividindo dados de treinamento e teste\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFm6J8sOxRg0"
   },
   "outputs": [],
   "source": [
    "# criando o modelo\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(x_train.shape[1],)),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "uOTSy6YGzO6V",
    "outputId": "9a590778-8b80-4728-990f-4fb86f638d56"
   },
   "outputs": [],
   "source": [
    "# visualizando o modelo\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ofmy8XI3yXch"
   },
   "outputs": [],
   "source": [
    "# compiando o modelo, adicionando metricas para visualizar e a função de perda\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy', 'precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeA2K7Vhyq4K",
    "outputId": "86ced8fc-6d4a-4844-af3f-c3b2d6f51504"
   },
   "outputs": [],
   "source": [
    "# Valiando e analizando as dimenções dos dados que irão para o modelo\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYob2bS3yth7",
    "outputId": "2d6bf93e-fa04-40c5-a45f-2b038cd7f526"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWMuRmvayv9B",
    "outputId": "4d67d094-d49c-4d9c-94a0-da973cea905e"
   },
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAzgCPnVy6qr",
    "outputId": "010b30a5-4205-4f33-a900-b5f7e6852fdb"
   },
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adicinando early stoping para diminuir o overfit do modelo e parar e fazer um treinamento mais eficiente\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxelDmhByV8A",
    "outputId": "9a0cf6bf-9632-4899-d643-5c55be27744c"
   },
   "outputs": [],
   "source": [
    "# treinando o modelo\n",
    "\n",
    "result = model.fit(x_train, y_train, epochs=25, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando os resultados do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "sGL64Xx1_9Ne",
    "outputId": "63f1780e-9a37-4a91-ef0a-083452466abc"
   },
   "outputs": [],
   "source": [
    "# visão temporal da performance do modelo\n",
    "\n",
    "history = result.history\n",
    "fig = px.line(x=list(range(1, 26)), y=history['loss'], labels={'x': 'Épocas', 'y': 'Perda'}, title='Função de Custo durante o Treinamento')\n",
    "fig.update_traces(mode='lines+markers')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "FiL4-WjYJqxo",
    "outputId": "81065056-526b-4d43-9c6f-923ad383cb3b"
   },
   "outputs": [],
   "source": [
    "# matriz de confusão para avaliação da distribuição de erros do modelo\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.models import load_model\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_classes)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "1818bNL83CZS",
    "outputId": "12014f26-b128-4d88-b256-a686baf92486"
   },
   "outputs": [],
   "source": [
    "# gráfico da loss durante o treinamento\n",
    "\n",
    "plt.plot(result.history['loss'], label='loss')\n",
    "plt.plot(result.history['val_loss'], label='val_loss')\n",
    "plt.legend(['Erro Treino', 'Erro Teste'])\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Função de Custo')\n",
    "plt.title('Training Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "UCIN40aMACtd",
    "outputId": "30a108a0-83ce-450e-e2b4-1a221fc41fd8"
   },
   "outputs": [],
   "source": [
    "# Análizando a precisão e a perda do modelo\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Line(x=list(range(1, 26)), y=history['accuracy'], mode='lines+markers', name='Precisão de Treinamento'))\n",
    "\n",
    "fig.add_trace(go.Line(x=list(range(1, 26)), y=history['val_loss'], mode='lines+markers', name='Perda de Validação'))\n",
    "\n",
    "fig.update_layout(title='Precisão e Perda durante o Treinamento', xaxis_title='Épocas', yaxis_title='Valor', legend_title='Métrica')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SmnkdbON7ZJf",
    "outputId": "4203ddf0-8464-41db-fdf1-558bb09d6563"
   },
   "outputs": [],
   "source": [
    "# ploanto a arquitetura do modelo\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_visualization.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
