{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zxSCLwPo7ONr",
    "outputId": "cdd98442-294f-4b27-b373-224e4bdcd87c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7yzqDjuJVxr",
    "outputId": "31f7487a-4467-4d83-ad77-d9d3899aeaf3"
   },
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taCv9mWi3DRx",
    "outputId": "25254aaa-db00-47d3-8cbe-e891cdcdcc2e"
   },
   "outputs": [],
   "source": [
    "%pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCdINVejOt6E"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import gdown\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "from sklearn.calibration import calibration_curve\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "DyiXPxqLJbsb",
    "outputId": "ba9e364c-1ae1-44dd-c4fb-bbe1eed45ef4"
   },
   "outputs": [],
   "source": [
    "df_premissa = \"1Tai4rHDM0P9lGX-kR9gyxAQ80eL8r4SC\"\n",
    "url_fraudes = f\"https://drive.google.com/uc?id={df_premissa}\"\n",
    "gdown.download(url_fraudes, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSiBp2JHJ4On"
   },
   "outputs": [],
   "source": [
    "## https://drive.google.com/file/d/1Tai4rHDM0P9lGX-kR9gyxAQ80eL8r4SC/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38ypkj8g7PQv"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = pd.read_parquet('/content/pre_processado_pf.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN4ph0X3zJGc"
   },
   "outputs": [],
   "source": [
    "y = dataframe_pj_premissa['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].values\n",
    "X = dataframe_pj_premissa.drop(['MATRICULA','DESCRICAO_IRREGULARIDADE IDENTIFICADA'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSYszgHggtMX"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFm6J8sOxRg0",
    "outputId": "8c240d33-a6f6-4c23-e2e5-472b3f4b3ce7"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(124, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy', 'precision'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "result = model.fit(X_train, y_train, epochs=60, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "Y-dSKfvfE-NX",
    "outputId": "e03f161e-9cc7-4302-b03f-593556f68369"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Supondo que `result` é o objeto retornado pelo `model.fit`\n",
    "plot_loss(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "H1iyqmjwQpRV",
    "outputId": "0ae4932a-54c1-4d05-b0de-6285cdfe1595"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "EL4E3MVUSikT",
    "outputId": "d93fc3a2-325a-41f3-cf20-a2cdb1f78e18"
   },
   "outputs": [],
   "source": [
    "model_para_timeseares = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(20, 20)),\n",
    "        layers.Conv1D(\n",
    "            filters=32,\n",
    "            kernel_size=7,\n",
    "            padding=\"same\",\n",
    "            strides=2,\n",
    "            activation=\"relu\",\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1D(\n",
    "            filters=16,\n",
    "            kernel_size=7,\n",
    "            padding=\"same\",\n",
    "            strides=2,\n",
    "            activation=\"relu\",\n",
    "        ),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=16,\n",
    "            kernel_size=7,\n",
    "            padding=\"same\",\n",
    "            strides=2,\n",
    "            activation=\"relu\",\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Conv1DTranspose(\n",
    "            filters=32,\n",
    "            kernel_size=7,\n",
    "            padding=\"same\",\n",
    "            strides=2,\n",
    "            activation=\"relu\",\n",
    "        ),\n",
    "        layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
    "    ]\n",
    ")\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_XPgVSKF7x7S"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model_PF.pkl\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "NPdjsL4o9fJG",
    "outputId": "8fab9fe5-92c4-4bc9-a8d1-acac75796bb1"
   },
   "outputs": [],
   "source": [
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes))\n",
    "\n",
    "y_pred_prob = model.predict(X_test).ravel()\n",
    "roc_auc = roc_auc_score(y_test, y_pred_classes)\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_classes)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'AUC-ROC (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLWawi6Cx4qL"
   },
   "source": [
    "### Curva ROC\n",
    "\n",
    "AUC-ROC (Área Sob a Curva): A área sob a curva ROC é uma métrica que varia entre 0 e 1. Neste caso, o AUC-ROC é 0.70, o que indica que o modelo tem uma habilidade moderada de distinguir entre as classes positivas e negativas. Quanto mais próximo de 1, melhor o desempenho.\n",
    "\n",
    "Eixo Y (True Positive Rate): Taxa de verdadeiros positivos, ou seja, a proporção de casos positivos corretamente identificados pelo modelo.\n",
    "\n",
    "Eixo X (False Positive Rate): Taxa de falsos positivos, que indica a proporção de casos negativos incorretamente classificados como positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "9kNAIjf3JESH",
    "outputId": "35469b4a-0cc1-4438-d5a4-92b8ff6224dd"
   },
   "outputs": [],
   "source": [
    "plt.plot(result.history['precision'], label='Precisão Treinamento')\n",
    "plt.plot(result.history['val_precision'], label='Precisão Validação')\n",
    "plt.title('Curva de Precisão durante o Treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Precisão')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1ABKKPmyCOU"
   },
   "source": [
    "### Curva de Precisão durante o Treinamento\n",
    "\n",
    "Eixo Y (Precisão): A métrica de precisão para o modelo ao longo do tempo, que é a proporção de previsões corretas feitas em relação a todas as previsões feitas.\n",
    "Eixo X (Épocas): As épocas são o número de vezes que o modelo percorreu o conjunto de dados durante o treinamento.\n",
    "\n",
    "Vemos uma melhora progressiva tanto no treinamento quanto na validação, mas com algumas oscilações na validação, o que pode indicar que o modelo está ajustando de maneira instável ao conjunto de validação em certas épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "KZ9l4-7V-SkY",
    "outputId": "5850b19a-cc05-4e36-ffd1-755e402e7774"
   },
   "outputs": [],
   "source": [
    "plt.plot(result.history['loss'], label='Perda Treinamento')\n",
    "plt.plot(result.history['val_loss'], label='Perda Validação')\n",
    "plt.title('Curva de Perda durante o Treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLVMVFuSyP_6"
   },
   "source": [
    "### Loss\n",
    "\n",
    "Eixo Y (Perda): Representa a função de perda (error) que o modelo tenta minimizar. No caso de classificação binária, a perda comumente usada é a entropia cruzada.\n",
    "Eixo X (Épocas): Assim como no gráfico anterior, as épocas representam o progresso do treinamento.\n",
    "\n",
    "A loss do treinamento e validação diminuem ao longo do tempo, indicando que o modelo está aprendendo. No entanto, há um comportamento instável na loss de validação, sugerindo que o modelo pode estar sofrendo com variações durante as diferentes épocas (possivelmente devido à variação nos dados de validação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "5KHsnPqr-UuG",
    "outputId": "85fb076c-1bf8-4ea9-8aed-ed9d3fcfcda5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.title('Curva de Precisão-Recall')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1nu9hLQyb2F"
   },
   "source": [
    "### Precisão-Recall\n",
    "\n",
    "A curva precisão-recall é útil em cenários com classes desbalanceadas. A curva decrescente sugere que, à medida que o modelo tenta maximizar o recall (encontrar mais verdadeiros positivos), a precisão diminui, o que é um comportamento esperado.\n",
    "\n",
    "Eixo Y (Precisão): A proporção de previsões corretas feitas pelo modelo em relação ao número total de previsões.\n",
    "Eixo X (Recall): Taxa de verdadeiros positivos sobre todos os exemplos positivos. Ou seja, o quão bem o modelo consegue encontrar todas as instâncias positivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "w07YCpDdzweE",
    "outputId": "f90987c1-15ff-4b3c-9559-5400cfcb9f8c"
   },
   "outputs": [],
   "source": [
    "prob_true, prob_pred = calibration_curve(y_test, y_pred_prob, n_bins=10)\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibrated')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfect Calibration')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.title('Calibration Plot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TtaR4ob4ZOH"
   },
   "source": [
    "## Calibration Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlvMp6Ox4cDq"
   },
   "source": [
    "Calibration Plot (Gráfico de Calibração), é utilizado para avaliar se as probabilidades previstas por um modelo estão bem calibradas, ou seja, se os valores de probabilidade estimados pelo modelo correspondem à frequência real dos eventos.\n",
    "\n",
    "\n",
    "O gráfico mostra que a linha azul está próxima da linha de calibração perfeita (linha laranja tracejada), o que sugere que as probabilidades previstas pelo modelo estão bem calibradas em várias regiões, especialmente para previsões acima de 0.6.\n",
    "\n",
    "Desvio abaixo de 0.4: Para valores de probabilidade menores que 0.4, o modelo tende a ser um pouco menos calibrado, prevendo probabilidades que subestimam a verdadeira taxa de eventos.\n",
    "\n",
    "Acima de 0.4: A linha azul se alinha bem à linha de calibração perfeita, sugerindo que, para previsões acima de 0.4, o modelo está fornecendo probabilidades bastante precisas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "pIykyDTx7o_O",
    "outputId": "1d64ccfa-c6b4-4562-bde4-89ceb74e4743"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "thresholds = np.arange(0, 1.1, 0.1)\n",
    "f1_scores = [f1_score(y_test, (y_pred_prob >= t).astype(int)) for t in thresholds]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, f1_scores, marker='o', color='b', label='F1 Score')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score vs Threshold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EdeA4Nr8Piq"
   },
   "source": [
    "### F1 vs Limiar de decisão\n",
    "\n",
    "O F1 Score varia conforme ajustamos o limiar (threshold) de decisão. O F1 Score é uma métrica que equilibra precisão e recall. Podemos ver que o melhor F1 Score ocorre quando o threshold está em torno de 0.2 a 0.4. Isso indica que, neste intervalo, o modelo consegue o melhor equilíbrio entre precisão e recall. À medida que o threshold aumenta (mais próximo de 1.0), o F1 Score cai drasticamente, sugerindo que o modelo se torna mais conservador, classificando cada vez mais exemplos como negativos, o que diminui o recall, e, consequentemente, o F1 Score.\n",
    "\n",
    "Ponto de Otimização: O threshold de 0.3 parece ser o ideal, já que o F1 Score está no seu ponto máximo aqui. Ajustar o modelo para trabalhar com esse threshold pode proporcionar uma melhor performance geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "X23jG-S87rW8",
    "outputId": "01114138-b639-4236-f624-296a25a49214"
   },
   "outputs": [],
   "source": [
    "sorted_pred_probs = np.sort(y_pred_prob)[::-1]\n",
    "sorted_true_labels = y_test[np.argsort(y_pred_prob)[::-1]]\n",
    "\n",
    "cumulative_gains = np.cumsum(sorted_true_labels)\n",
    "total_positives = np.sum(y_test)\n",
    "cumulative_gains = cumulative_gains / total_positives\n",
    "\n",
    "plt.plot(np.arange(1, len(y_test) + 1) / len(y_test), cumulative_gains, label='Cumulative Gain')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('Fraction of Samples')\n",
    "plt.ylabel('Cumulative Gains')\n",
    "plt.title('Cumulative Gain Chart')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gonbosKv8pIQ"
   },
   "source": [
    "### Cumulative Gain\n",
    "\n",
    "Este gráfico deve mostrar o ganho cumulativo que o modelo proporciona comparado a um classificador aleatório. Contudo, neste caso, o ganho cumulativo mostrado é praticamente uma linha reta na base, o que indica que o modelo não está fornecendo ganho sobre o classificador aleatório. Isso é um sinal de que o modelo pode estar com dificuldades para classificar corretamente os exemplos positivos ou que pode estar superajustado ou subajustado, já que os exemplos positivos não estão sendo classificados com eficiência.\n",
    "\n",
    "Ação Recomendável: É possível que o modelo necessite de ajustes na calibração das predições ou na escolha do algoritmo, pois o comportamento do gráfico sugere que ele está falhando em capturar os padrões necessários para discriminar corretamente os exemplos positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "30g0AM077ssC",
    "outputId": "0d143ea9-fc92-441f-b59d-18de25f6aab1"
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.2f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4QXk4Fpw8e5j"
   },
   "source": [
    " ### Precisão vs Recall\n",
    "\n",
    " A curva de precisão e recall mostra a relação entre as duas métricas à medida que ajustamos o threshold de decisão. O valor da AUC (Área Sob a Curva) é de 0.79, o que indica que o modelo tem uma boa capacidade de manter um equilíbrio entre precisão e recall. A curva começa alta (próximo de 1.0 tanto em precisão quanto em recall) e diminui à medida que o recall aumenta, o que é esperado.\n",
    "\n",
    "O valor da AUC de 0.79 é bom, sugerindo que o modelo pode ser eficaz, mas ainda há espaço para melhorias. Para problemas desbalanceados, como o que você provavelmente está enfrentando, essa curva é mais relevante do que a curva ROC. A queda acentuada da precisão para recalls mais altos indica que, ao tentar capturar mais exemplos positivos (aumentando o recall), a precisão diminui significativamente, sugerindo que o modelo está cometendo mais erros ao identificar falsos positivos."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
