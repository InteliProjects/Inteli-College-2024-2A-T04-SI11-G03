{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUhHmPliWe4I"
   },
   "source": [
    "# Importação das Bibliotecas que serão utilizadas no Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZJUNl10I3JW"
   },
   "source": [
    "### Aqui segue o pré-processamento e o que foi feito nas Sprints 1 e 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuPRD6dbGSOd",
    "outputId": "ad73a239-6d26-46aa-9f29-df1ae28085b5"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E7dzFab-JL9Z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpHUfSncWpaO"
   },
   "source": [
    "## Download dos arquivos contendo os datasets de consumo desde 2019 a 2024\n",
    "  - Aqui retiramos a base de 2020, por conta da pandemia do Coronavírus. Foi uma escolha do grupo devido à possibilidade de discrepância nas leituras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EG9a2W-kzQXc",
    "outputId": "98aa18af-3aad-4054-b721-0c7f9b5d2240"
   },
   "outputs": [],
   "source": [
    "arquivo_destino_base = \"dataset_{}.csv\"\n",
    "\n",
    "ids = {\n",
    "    \"consumo_2024\": \"1-iXT7eaJWQokHf9cyfrB8N5wvkdhgjJW\",\n",
    "    \"consumo_2023\": \"1-WfvkRwaRr85B_Joxcm9xVdpyg5NBAmp\",\n",
    "    \"consumo_2022\": \"1-Uu4Tf4lufJVFeJnYKc5w7OeW66pe1eC\",\n",
    "    \"consumo_2021\": \"1-2PsTLzG4dcY4wM0p7vFfabUuLv950gC\",\n",
    "    \"consumo_2020\": \"1-1pOoa0eJlNJ94BMi7p4PTx5KUS96mhX\",\n",
    "    \"consumo_2019\": \"1-2PsTLzG4dcY4wM0p7vFfabUuLv950gC\",\n",
    "    \"CONSUMO_GERAL\": \"1-IOqfwmh_tTIDHeOer8J-HkGFtwuX67g\",\n",
    "}\n",
    "\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "\n",
    "for key, file_id in ids.items():\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    arquivo_destino = arquivo_destino_base.format(key)\n",
    "\n",
    "    gdown.download(url, arquivo_destino, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2OFwaINKz9a2",
    "outputId": "b1a93913-9b71-4e66-ac77-074a3cd34980"
   },
   "outputs": [],
   "source": [
    "arquivos_csv = [\n",
    "    \"./dataset_consumo_2024.csv\",\n",
    "    \"./dataset_consumo_2023.csv\",\n",
    "    \"./dataset_consumo_2022.csv\",\n",
    "    \"./dataset_consumo_2021.csv\",\n",
    "    \"./dataset_consumo_2019.csv\",\n",
    "]\n",
    "\n",
    "ALL_COLUMNS_CONSUMO_GERAL = pd.concat([pd.read_csv(arquivo, delimiter=\";\") for arquivo in arquivos_csv], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkGPmDOtKmkN"
   },
   "outputs": [],
   "source": [
    "consumo_geral = pd.read_csv('/content/dataset_CONSUMO_GERAL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7-Y6UF0XCuM"
   },
   "source": [
    "## Download do dataset com o Target das Fraudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ULyqg7TpoDYI",
    "outputId": "aff60c8d-66ee-4612-a8f5-fbaf298578ec"
   },
   "outputs": [],
   "source": [
    "file_id_fraudes = \"1-MbIlChqQapcxFkoJgpbQIsN9FBLfbX1\"\n",
    "url_fraudes = f\"https://drive.google.com/uc?id={file_id_fraudes}\"\n",
    "\n",
    "gdown.download(url_fraudes, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6w7_peSCn7Ug"
   },
   "outputs": [],
   "source": [
    "fraudes = pd.read_csv('/content/fraudes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldtmRy7UXLY3"
   },
   "source": [
    "### A tabela \"ALL_COLUMNS_CONSUMO_GERAL\" possui todas as tabelas de consumo e a partir disso decidimos considerar algumas colunas categóricas que podem ajudar a melhorar o desempenho do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "UOb4m0J-5TCL",
    "outputId": "4a4b199a-59c5-4bf5-f072-68ff96547070"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_EHJc8LXlev"
   },
   "source": [
    "### Remoção de colunas indesejadas até o momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jC1ItnrL4iiS"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL = ALL_COLUMNS_CONSUMO_GERAL.drop(columns=['Unnamed: 0', 'EMP_CODIGO', 'COD_GRUPO', 'COD_SETOR_COMERCIAL', 'NUM_QUADRA', 'COD_ROTA_LEITURA', 'SEQ_RESPONSAVEL', 'ECO_RESIDENCIAL', 'ECO_COMERCIAL', 'ECO_INDUSTRIAL', 'ECO_PUBLICA', 'ECO_OUTRAS','LTR_ATUAL', 'LTR_COLETADA', 'DAT_LEITURA', 'DIAS_LEITURA', 'COD_LEITURA_INF_1', 'COD_LEITURA_INF_2', 'COD_LEITURA_INF_3', 'HORA_LEITURA', 'DSC_SIMULTANEA', 'COD_LEITURA_INT','EXCECAO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbkHY73-EKfq",
    "outputId": "c32d0cf9-bc07-452d-fd11-432cf9682604"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noqyuFdPXq6m"
   },
   "source": [
    "### Nessa seção queriamos validar a tabela de \"VOLUME_ESTIMADO_ACUM\" para ver se ela poderia agregar dentro do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "rXw_shC3ETEC",
    "outputId": "b20e80d4-df14-4595-abfd-97204fe48ac3"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL[['VOLUME_ESTIMADO_ACUM']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "QQpwtHo1EQR1",
    "outputId": "1b87e121-4002-4dd2-df33-92c949a99177"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL[ALL_COLUMNS_CONSUMO_GERAL['VOLUME_ESTIMADO'] != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpDnM5voX7uN"
   },
   "source": [
    "#### O insight retirado aqui é que talvez a melhor coluna para validação e ser utilizada como featura no modelo é a coluna de Volume Estimado. Ela possui maior consistência nos resultados, do que a coluna de Volume Estimado Acumulado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSkEsnRrZxSk"
   },
   "source": [
    "### Separação de Features relevantes\n",
    "\n",
    "Após pesquisas e visualizar as colunas disponíveis, percebemos uma coluna que poderia ser interessante para o processo de identificação de fraude. A coluna de \"DSC_OCORRENCIA\". Ela basicamente corresponde a descrição de como foi o processo de vistoria e coleta do responsável e em cada um dos domicílios (matrícula)\n",
    "\n",
    "Isso surgiu como uma possibilidade de tentar direcionar o modelo para casos nos quais há uma maior possibilidade de uma fraude, de acordo com a visualização do medidor em cada um desses domicílios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XGr7R_w_Kei0",
    "outputId": "ebec7847-f2c8-4953-8e2e-127c319e5940"
   },
   "outputs": [],
   "source": [
    "ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI = ALL_COLUMNS_CONSUMO_GERAL[ALL_COLUMNS_CONSUMO_GERAL['DSC_OCORRENCIA'].isin([\n",
    "    'NORMAL',\n",
    "    'MEDIDOR RETIRADO/FURTADO',\n",
    "    'LEITURA COLETADA PELO CLIENTE',\n",
    "    'MEDIDOR NÃO LOCALIZADO',\n",
    "    'IMÓVEL DESOCUPADO'\n",
    "])]\n",
    "\n",
    "ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2h0_spJ_rGdD"
   },
   "source": [
    "## Tratando Dataframe com mais colunas targets adicionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEWOIr3RbEGS"
   },
   "source": [
    "#### Seperação do Dataframe apenas para a visualização das matriculas com Categoria Pessoa Jurídica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "id_RoNM8ZUGh",
    "outputId": "753f9855-eef1-4556-d0dc-f519fc860ec5"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI[ALL_COLUMNS_CONSUMO_GERAL_PREMISSA_VINI[\"CATEGORIA\"].isin([\"COMERCIAL\", \"PUBLICA\", \"INDUSTRIAL\"])]\n",
    "dataframe_pj_premissa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jjuI7kQgbPQl"
   },
   "source": [
    "### Processo de One Hot Encoding para as Colunas, as quais serão as features para o nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tZlsXF8r0Ojo"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = pd.get_dummies(dataframe_pj_premissa, columns=['TIPO_LIGACAO', 'DSC_OCORRENCIA', 'STA_TROCA', 'STA_ACEITA_LEITURA'], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2J6lQ4lSR884",
    "outputId": "578bec35-c495-4e4c-938e-079f8969924f"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nIyTxQ03lDv",
    "outputId": "8c463ee9-39e4-437f-93c8-fd4c01742444"
   },
   "outputs": [],
   "source": [
    "fraudes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "6bDV-ReHLWDi",
    "outputId": "74dc401f-7129-47c8-c2aa-5815876b0404"
   },
   "outputs": [],
   "source": [
    "fraudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sqp4unc3MG-"
   },
   "outputs": [],
   "source": [
    "dataframe_fraudes_premissa = fraudes[['MATRICULA', 'DESCRICAO']].drop_duplicates()\n",
    "dataframe_fraudes_premissa = pd.get_dummies(dataframe_fraudes_premissa, columns=['DESCRICAO'], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVlUTM94tGEY",
    "outputId": "ca0e24b3-4acb-4ca5-820f-3393b8666195"
   },
   "outputs": [],
   "source": [
    "dataframe_fraudes_premissa['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PRc72FL9vIKC",
    "outputId": "a3dcd62d-fb3f-4a2f-cf89-7e0fc9754a40"
   },
   "outputs": [],
   "source": [
    "len(dataframe_fraudes_premissa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fMcRIGX4Tub"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = pd.merge(dataframe_pj_premissa, dataframe_fraudes_premissa, on='MATRICULA', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jWa718hq5QpO",
    "outputId": "d415d320-b9f1-4d36-b57a-fd5df08f836d"
   },
   "outputs": [],
   "source": [
    "# dataframe_pj_premissa.drop_duplicates(subset=\"MATRICULA\", keep='first')\n",
    "dataframe_pj_premissa.dropna(subset=\"REFERENCIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIPLa_N6uwna"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = dataframe_pj_premissa.dropna(subset=\"COD_LATITUDE\")\n",
    "dataframe_pj_premissa = dataframe_pj_premissa.dropna(subset=\"COD_LONGITUDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pahOXuPpIwMm"
   },
   "source": [
    "# Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnlfnEVaUjeN"
   },
   "source": [
    "### Agrupamento dos clusteres por Latitude e Longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjXMQWnercTr"
   },
   "source": [
    "Aqui removendo os outliers nas colunas de latitude e longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFrN4XBsrcBS"
   },
   "outputs": [],
   "source": [
    "def remove_rows_with_column_value_greater_than_one(df, column_names):\n",
    "    condition = (df[column_names] > -10).any(axis=1)\n",
    "\n",
    "    df_filtered = df[~condition]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "dataframe_pj_premissa = remove_rows_with_column_value_greater_than_one(dataframe_pj_premissa, ['COD_LATITUDE', 'COD_LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b2uBdLiWUqLK",
    "outputId": "134aed78-9a7d-4683-98b7-dcb56cc1e395"
   },
   "outputs": [],
   "source": [
    "def plotar(n_clusters):\n",
    "\n",
    "  df_temp = dataframe_pj_premissa.copy()\n",
    "  kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "  df_temp['cluster'] = kmeans.fit_predict(dataframe_pj_premissa[['COD_LATITUDE', 'COD_LONGITUDE']])\n",
    "\n",
    "  # visualizando\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  plt.scatter(dataframe_pj_premissa['COD_LONGITUDE'], dataframe_pj_premissa['COD_LATITUDE'], c=df_temp['cluster'], cmap='viridis', marker='o', s=100)\n",
    "  plt.title(f\"K-Means Clustering com {n_clusters} Clusters\")\n",
    "  plt.xlabel(\"Longitude\")\n",
    "  plt.ylabel(\"Latitude\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# visulizar clusters do range de 2 para 17\n",
    "for x in range(2, 17):\n",
    "  print()\n",
    "  plotar(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ0J_PpZr_K7",
    "outputId": "18e18e3d-30ba-49e8-a023-f830460596f0"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=20, random_state=42)\n",
    "dataframe_pj_premissa['cluster'] = kmeans.fit_predict(dataframe_pj_premissa[['COD_LATITUDE', 'COD_LONGITUDE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TI8fEIeKsjSh"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = dataframe_pj_premissa.drop(columns=['COD_LATITUDE', 'COD_LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnYIOvoeszaa"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa = pd.get_dummies(dataframe_pj_premissa, columns = ['cluster'], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKk7toKYflb8"
   },
   "source": [
    "### Normalizando com o Robust Scaler\n",
    "\n",
    "O RobustScaler é uma técnica de normalização usada para transformar dados. Ele é útil especialmente quando os dados contêm outliers, ou seja, valores atípicos que podem distorcer (neste caso o Consumo e o Volume) os resultados de outras técnicas de escalonamento, como StandardScaler ou MinMaxScaler.\n",
    "\n",
    "O RobustScaler transforma os dados subtraindo a mediana e dividindo pela amplitude interquartil (IQR, Interquartile Range). A mediana é o valor do ponto médio quando os dados são ordenados, e o IQR é a diferença entre o terceiro quartil (75º percentil) e o primeiro quartil (25º percentil).\n",
    "\n",
    "Esse método é menos sensível a outliers porque, ao contrário da média e do desvio padrão (usados pelo StandardScaler), a mediana e o IQR não são afetados por valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sizbtxDrUkvL"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "dataframe_pj_premissa[['CONS_MEDIDO']] = scaler.fit_transform(dataframe_pj_premissa[['CONS_MEDIDO']])\n",
    "dataframe_pj_premissa[['VOLUME_ESTIMADO']] = scaler.fit_transform(dataframe_pj_premissa[['VOLUME_ESTIMADO']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "Gb041Z7n7zUf",
    "outputId": "9268826a-792b-4e11-c5cb-091084893394"
   },
   "outputs": [],
   "source": [
    "pivoted_df = pd.pivot_table(\n",
    "    dataframe_pj_premissa,\n",
    "    index='MATRICULA',\n",
    "    columns='REFERENCIA',\n",
    "    values=['CONS_MEDIDO', 'VOLUME_ESTIMADO'],\n",
    "    aggfunc='sum'\n",
    ")\n",
    "\n",
    "pivoted_df.columns = ['_'.join(col).strip() for col in pivoted_df.columns.values]\n",
    "pivoted_df = pivoted_df.reset_index()\n",
    "\n",
    "pivoted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh6Wog6Wv2ks",
    "outputId": "b2a65891-6bc6-4203-fd10-2cc01586236d"
   },
   "outputs": [],
   "source": [
    "len(pivoted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzm0etx4f39Y"
   },
   "source": [
    "### Atribuição de cada uma das variáveis categóricas ao dataframe com o consumo e volume históricos\n",
    "\n",
    "- É importante citar aqui que atribuímos a premissa que a primeira definição de tipo de ligação, descrição e os outros utilizados, serão os que tomaremos como base para inferência dentro do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEg8bcZ8AWmA"
   },
   "outputs": [],
   "source": [
    "tipo_ligacao = dataframe_pj_premissa[['MATRICULA','TIPO_LIGACAO_Consumo Fixo', 'TIPO_LIGACAO_Hidrometrado']].drop_duplicates(subset='MATRICULA', keep='first')\n",
    "pivoted_df = pivoted_df.merge(tipo_ligacao, on='MATRICULA', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2Aj6H_iBS6h"
   },
   "outputs": [],
   "source": [
    "descricao_ocorrencia = dataframe_pj_premissa[['MATRICULA','DSC_OCORRENCIA_MEDIDOR NÃO LOCALIZADO', 'DSC_OCORRENCIA_MEDIDOR RETIRADO/FURTADO', 'DSC_OCORRENCIA_NORMAL']].drop_duplicates(subset='MATRICULA', keep='first')\n",
    "pivoted_df = pivoted_df.merge(descricao_ocorrencia, on='MATRICULA', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faW98EliCUo6"
   },
   "outputs": [],
   "source": [
    "fraude_ou_não = dataframe_pj_premissa[['MATRICULA','DESCRICAO_IRREGULARIDADE IDENTIFICADA']].drop_duplicates(subset='MATRICULA', keep='first')\n",
    "pivoted_df = pivoted_df.merge(fraude_ou_não, on='MATRICULA', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIMOhvMIywR7",
    "outputId": "cd5127d7-fe3b-4b7b-f167-07c86c524e1f"
   },
   "outputs": [],
   "source": [
    "dataframe_pj_premissa.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0N-8ppTs7Ky"
   },
   "outputs": [],
   "source": [
    "clusters = dataframe_pj_premissa[['MATRICULA','cluster_0', 'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4',\n",
    "       'cluster_5', 'cluster_6', 'cluster_7', 'cluster_8', 'cluster_9',\n",
    "       'cluster_10', 'cluster_11', 'cluster_12', 'cluster_13',\n",
    "       'cluster_14', 'cluster_15', 'cluster_16', 'cluster_17',\n",
    "       'cluster_18', 'cluster_19']].drop_duplicates(subset='MATRICULA', keep='first')\n",
    "pivoted_df = pivoted_df.merge(clusters, on='MATRICULA', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Po2Vj6o9Smj"
   },
   "outputs": [],
   "source": [
    "pivoted_df = pivoted_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "0U6g1CIhDdtA",
    "outputId": "c5754fc3-4ff1-4819-e3c5-8cfd438e2c4e"
   },
   "outputs": [],
   "source": [
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WX4wNVRQwJ5g"
   },
   "outputs": [],
   "source": [
    "colunas_data = ['CONS_MEDIDO_2019-01-01', 'CONS_MEDIDO_2019-02-01',\n",
    "       'CONS_MEDIDO_2019-03-01', 'CONS_MEDIDO_2019-04-01',\n",
    "       'CONS_MEDIDO_2019-05-01', 'CONS_MEDIDO_2019-06-01',\n",
    "       'CONS_MEDIDO_2019-07-01', 'CONS_MEDIDO_2019-08-01',\n",
    "       'CONS_MEDIDO_2019-09-01', 'CONS_MEDIDO_2019-10-01',\n",
    "       'CONS_MEDIDO_2019-11-01', 'CONS_MEDIDO_2019-12-01',\n",
    "       'CONS_MEDIDO_2022-01-01', 'CONS_MEDIDO_2022-02-01',\n",
    "       'CONS_MEDIDO_2022-03-01', 'CONS_MEDIDO_2022-04-01',\n",
    "       'CONS_MEDIDO_2022-05-01', 'CONS_MEDIDO_2022-06-01',\n",
    "       'CONS_MEDIDO_2022-07-01', 'CONS_MEDIDO_2022-08-01',\n",
    "       'CONS_MEDIDO_2022-09-01', 'CONS_MEDIDO_2022-10-01',\n",
    "       'CONS_MEDIDO_2022-11-01', 'CONS_MEDIDO_2022-12-01',\n",
    "       'CONS_MEDIDO_2023-01-01', 'CONS_MEDIDO_2023-02-01',\n",
    "       'CONS_MEDIDO_2023-03-01', 'CONS_MEDIDO_2023-04-01',\n",
    "       'CONS_MEDIDO_2023-05-01', 'CONS_MEDIDO_2023-06-01',\n",
    "       'CONS_MEDIDO_2023-07-01', 'CONS_MEDIDO_2023-08-01',\n",
    "       'CONS_MEDIDO_2023-09-01', 'CONS_MEDIDO_2023-10-01',\n",
    "       'CONS_MEDIDO_2023-11-01', 'CONS_MEDIDO_2023-12-01',\n",
    "       'CONS_MEDIDO_2024-01-01', 'CONS_MEDIDO_2024-02-01',\n",
    "       'CONS_MEDIDO_2024-03-01', 'CONS_MEDIDO_2024-04-01',\n",
    "       'CONS_MEDIDO_2024-05-01', 'CONS_MEDIDO_2024-06-01',\n",
    "       'CONS_MEDIDO_2024-07-01', 'CONS_MEDIDO_2024-08-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_fOIfAWwwv1",
    "outputId": "68cae367-1f86-4428-fb1c-b908ab378b78"
   },
   "outputs": [],
   "source": [
    "np.unique(pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].values, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57gpeUyH-Bjx"
   },
   "source": [
    "## Rodando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBJ21gZSXzNg"
   },
   "source": [
    "### Divisão de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XAiaqzOm9hSY",
    "outputId": "4f9859b0-698a-4365-8f95-b50d37f49247"
   },
   "outputs": [],
   "source": [
    "pivoted_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPeNvcbLgh1h"
   },
   "source": [
    "#### Balanceando os dados com Smote (Synthetic Minority Over-sampling Technique)\n",
    "\n",
    "O smote é uma técnica de \"oversampling\" usada para balancear datasets com o objetivo de aumentar a quantidade de amostras da classe minoritária gerando novos exemplos sintéticos, em vez de simplesmente replicar os dados existentes. Isso ajuda a melhorar a performance de modelos de machine learning ao treinar com um dataset mais balanceado.\n",
    "\n",
    "Quando você treina um modelo de machine learning com um dataset desbalanceado (onde uma classe tem muito mais exemplos do que a outra), o modelo tende a favorecer a classe majoritária.\n",
    "\n",
    "Como resultado, o modelo pode ter um bom desempenho em termos de acurácia geral, mas um desempenho ruim ao identificar a classe minoritária (por exemplo, falhas, fraudes, etc.).\n",
    "\n",
    "O Smote ajuda a mitigar esse problema ao balancear o dataset, aumentando o número de exemplos da classe minoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Efy-miOag6Jq"
   },
   "outputs": [],
   "source": [
    "def balanciar(df):\n",
    "  smote = SMOTE(random_state=42)\n",
    "  X = pivoted_df.drop('DESCRICAO_IRREGULARIDADE IDENTIFICADA', axis=1)\n",
    "  y = pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA']\n",
    "  X_res, y_res = smote.fit_resample(X, y)\n",
    "  return pd.concat([X_res, y_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P74LnL6N9Ui"
   },
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# def balanciar(df):\n",
    "#   rus = RandomUnderSampler(random_state=42)\n",
    "#   X = pivoted_df.drop('DESCRICAO_IRREGULARIDADE IDENTIFICADA', axis=1)\n",
    "#   y = pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA']\n",
    "#   X_res, y_res = rus.fit_resample(X, y)\n",
    "#   return pd.concat([X_res, y_res], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alIELHxvdxrn"
   },
   "outputs": [],
   "source": [
    "# pivoted_df = balanciar(pivoted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7rhSEoIxijy",
    "outputId": "8876459f-d3f4-425d-cfbc-f82e93f56128"
   },
   "outputs": [],
   "source": [
    "np.unique(pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSuX6n27pLrJ"
   },
   "outputs": [],
   "source": [
    "pivoted_df = balanciar(pivoted_df.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyCp1ciayKba",
    "outputId": "5fd4e634-ac2d-4692-faab-c18e5fcd5be6"
   },
   "outputs": [],
   "source": [
    "pivoted_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VN4ph0X3zJGc"
   },
   "outputs": [],
   "source": [
    "y = pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].values\n",
    "X = pivoted_df.drop(['MATRICULA','DESCRICAO_IRREGULARIDADE IDENTIFICADA'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSYszgHggtMX"
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFm6J8sOxRg0"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(x_train.shape[1],)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(8, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "uOTSy6YGzO6V",
    "outputId": "0acdfc8a-643f-49fa-fea4-4b741767f73a"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ofmy8XI3yXch"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeA2K7Vhyq4K",
    "outputId": "d366df5b-e0e3-49c4-9732-b633e8c0ad9e"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYob2bS3yth7",
    "outputId": "6722d49a-b07c-4074-96fc-cbf4da3388d2"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWMuRmvayv9B",
    "outputId": "832c8e92-b78d-4f63-c829-41f701b0eeee"
   },
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAzgCPnVy6qr",
    "outputId": "6b4e61db-bf76-4011-f3c1-a46acec0c658"
   },
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxelDmhByV8A",
    "outputId": "25de0407-b22e-48e6-99d6-8cce9ec97c4a"
   },
   "outputs": [],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "result = model.fit(x_train, y_train, epochs=45, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "sGL64Xx1_9Ne",
    "outputId": "0ea75b5a-52ba-4a9c-cefa-54e6c5dded8e"
   },
   "outputs": [],
   "source": [
    "history = result.history\n",
    "fig = px.line(x=list(range(1, 46)), y=history['loss'], labels={'x': 'Épocas', 'y': 'Perda'}, title='Função de Custo durante o Treinamento')\n",
    "fig.update_traces(mode='lines+markers')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "FiL4-WjYJqxo",
    "outputId": "25e4cd3d-1f85-4e54-c846-5093a3b80163"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.models import load_model\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Não é fraude\", \"É fraude\"])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "1818bNL83CZS",
    "outputId": "628cd5d4-186d-451a-e6f2-a64e64439616"
   },
   "outputs": [],
   "source": [
    "plt.plot(result.history['loss'], label='loss')\n",
    "plt.plot(result.history['val_loss'], label='val_loss')\n",
    "plt.legend(['Erro Treino', 'Erro Teste'])\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Função de Custo')\n",
    "plt.title('Training Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "id": "UCIN40aMACtd",
    "outputId": "f5f2b75d-f540-4cf0-98eb-3b84032c7d5f"
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Line(x=list(range(1, 26)), y=history['accuracy'], mode='lines+markers', name='Precisão de Treinamento'))\n",
    "\n",
    "fig.add_trace(go.Line(x=list(range(1, 26)), y=history['val_loss'], mode='lines+markers', name='Perda de Validação'))\n",
    "\n",
    "fig.update_layout(title='Precisão e Perda durante o Treinamento', xaxis_title='Épocas', yaxis_title='Valor', legend_title='Métrica')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SmnkdbON7ZJf",
    "outputId": "5183a0ff-14ff-460f-ac5c-5741f3cdaa94"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_visualization.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oG5Id7b8T9tb"
   },
   "source": [
    "## Agregação de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jilqcvnKTUFe",
    "outputId": "0b2b6bd7-b9dc-448c-c58c-5be8ef8d41d5"
   },
   "outputs": [],
   "source": [
    "%pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXcHCMBnhu95"
   },
   "source": [
    "### Otimização Bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "midq3LIpWlxe",
    "outputId": "0a0d1e26-a48c-4bfd-f3da-ed01291c3b6f"
   },
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "# Definindo a função objetivo\n",
    "def objective(params):\n",
    "    learning_rate, num_neurons, batch_size, dropout_rate = params\n",
    "\n",
    "    # Pegando a última 'val_loss' como métrica para otimização\n",
    "    val_loss = result.history['val_loss'][-1]\n",
    "    return val_loss\n",
    "\n",
    "# Definindo o espaço de busca\n",
    "space = [\n",
    "    Real(1e-4, 1e-2, \"log-uniform\", name='learning_rate'),  # Taxa de aprendizado\n",
    "    Integer(16, 256, name='num_neurons'),                 # Número de neurônios\n",
    "    Integer(16, 128, name='batch_size'),                   # Tamanho do batch\n",
    "    Real(0.1, 0.5, name='dropout_rate')                   # Olhar pro dropout\n",
    "]\n",
    "\n",
    "# Otimizando usando a otimização bayesiana\n",
    "result = gp_minimize(objective, space, n_calls=30, random_state=42)\n",
    "\n",
    "print(f\"Melhores hiperparâmetros: {result.x}\")\n",
    "print(f\"Menor val_loss: {result.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv3mHOehW6HF",
    "outputId": "7dc9eb18-fc14-4065-9e9b-6826867fcac3"
   },
   "outputs": [],
   "source": [
    "print(f\"Melhor taxa de aprendizado: {result.x[0]}, Melhor número de neurônios: {result.x[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq4PwxaKd2_-"
   },
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKN5G3Uud5CS"
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate=0.001, dropout_rate=0.2):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(x_train.shape[1],)),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(8, activation='relu'),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "CKZm80JLqDK8",
    "outputId": "cdf5dc5e-5f34-4ce6-c6f4-baa28eceb996"
   },
   "outputs": [],
   "source": [
    "%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRZeSxTbnus-",
    "outputId": "9aa99be5-9944-4471-b79a-c824f5e57986"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "\n",
    "model = KerasClassifier(model=create_model, optimizer='adam')\n",
    "\n",
    "param_dist = {\n",
    "    'batch_size': [64, 128],\n",
    "    'epochs': [30, 45],\n",
    "}\n",
    "\n",
    "# Define the scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score)}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=1,\n",
    "    scoring=scoring,\n",
    "    refit='accuracy'\n",
    ")\n",
    "\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "print(random_search.best_params_)\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZTcRklgQV-Y",
    "outputId": "a4f96510-3581-4657-b044-d965a44ac2d2"
   },
   "outputs": [],
   "source": [
    "%pip install imblearn keras_tuner keras scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InTkinHGhUC0"
   },
   "source": [
    "### Rodando random search para a entender qual é a melhor definição do modelo\n",
    "\n",
    "Iteração anteriormente utilizada para o modelo PF, mas agora agregada para o modelo PJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXOeu034QEbd",
    "outputId": "f7e6994f-dc48-4573-89d7-e2407b557168"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "# Definindo a função para construir o modelo\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(x_train.shape[1],)))\n",
    "\n",
    "    # Hyperparameters para o número de unidades nas camadas\n",
    "    for i in range(hp.Int('num_layers', 2, 4)):  # entre 2 e 4 camadas densas\n",
    "        model.add(keras.layers.Dense(units=hp.Int(f'units_{i}', min_value=64, max_value=512, step=64), activation='relu'))\n",
    "        model.add(keras.layers.Dropout(rate=hp.Float(f'dropout_{i}', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Hyperparameters para o otimizador e a taxa de aprendizado\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', 'precision'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Definindo o tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='keras_tuning')\n",
    "\n",
    "# Iniciando o grid search\n",
    "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmsdScbQQBOP"
   },
   "source": [
    "### Testando LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKec3NOreIe_"
   },
   "source": [
    "A Long Short-Term Memory (LSTM) é uma arquitetura de rede neural recorrente (RNN) que foi projetada especificamente para aprender dependências de longo prazo em sequências de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiWen5BneL6n"
   },
   "source": [
    "Essa capacidade de aprender padrões complexos ao longo do tempo torna as LSTMs particularmente úteis para identificar situações de fraude, onde os padrões fraudulentos podem ser sutis, raros e distribuídos ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ruAXrApsRWvO",
    "outputId": "c1c2b3a9-aaa8-4f25-ebdb-362b0d24b41e"
   },
   "outputs": [],
   "source": [
    "pivoted_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuwOjWT-eOVn"
   },
   "source": [
    "Conversando com o orientador César, optamos por seguir com a proposta de dividir os dados categóricos dos númericos, visto que a LSTM poderia interpretar os valores categóricos como parte ou sequência dos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UQcWhrD3ZHWn"
   },
   "outputs": [],
   "source": [
    "X_numeric_seq = pivoted_df.drop(['MATRICULA','DESCRICAO_IRREGULARIDADE IDENTIFICADA', 'TIPO_LIGACAO_Consumo Fixo', 'TIPO_LIGACAO_Hidrometrado',\n",
    "       'DSC_OCORRENCIA_MEDIDOR NÃO LOCALIZADO',\n",
    "       'DSC_OCORRENCIA_MEDIDOR RETIRADO/FURTADO', 'DSC_OCORRENCIA_NORMAL',\n",
    "       'cluster_0', 'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4',\n",
    "       'cluster_5', 'cluster_6', 'cluster_7', 'cluster_8', 'cluster_9',\n",
    "       'cluster_10', 'cluster_11', 'cluster_12', 'cluster_13',\n",
    "       'cluster_14', 'cluster_15', 'cluster_16', 'cluster_17',\n",
    "       'cluster_18', 'cluster_19'], axis=1).values\n",
    "X_categorical_seq = pivoted_df[['TIPO_LIGACAO_Consumo Fixo', 'TIPO_LIGACAO_Hidrometrado',\n",
    "       'DSC_OCORRENCIA_MEDIDOR NÃO LOCALIZADO',\n",
    "       'DSC_OCORRENCIA_MEDIDOR RETIRADO/FURTADO', 'DSC_OCORRENCIA_NORMAL',\n",
    "       'cluster_0', 'cluster_1', 'cluster_2', 'cluster_3', 'cluster_4',\n",
    "       'cluster_5', 'cluster_6', 'cluster_7', 'cluster_8', 'cluster_9',\n",
    "       'cluster_10', 'cluster_11', 'cluster_12', 'cluster_13',\n",
    "       'cluster_14', 'cluster_15', 'cluster_16', 'cluster_17',\n",
    "       'cluster_18', 'cluster_19']].values\n",
    "y_seq = pivoted_df['DESCRICAO_IRREGULARIDADE IDENTIFICADA'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D0t2jSW3c0rL",
    "outputId": "69dc4944-e71b-406f-c0f5-36f98cb567b1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate\n",
    "\n",
    "# Divisão de dados em treino e teste\n",
    "X_train_num, X_test_num, X_train_cat, X_test_cat, y_train, y_test = train_test_split(X_numeric_seq, X_categorical_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definindo a entrada da sequência numérica\n",
    "numeric_input = Input(shape=(X_numeric_seq.shape[1], 1), name='numeric_input')\n",
    "\n",
    "# Camada LSTM para variáveis numéricas\n",
    "x_numeric = LSTM(64, return_sequences=False)(numeric_input)\n",
    "\n",
    "# Definindo a entrada da sequência categórica\n",
    "categorical_input = Input(shape=(X_categorical_seq.shape[1],), name='categorical_input')\n",
    "\n",
    "# Camada Densa para variáveis categóricas\n",
    "x_categorical = Dense(32, activation='relu')(categorical_input)\n",
    "\n",
    "# Concatenando as saídas das camadas numéricas e categóricas\n",
    "concatenated = Concatenate()([x_numeric, x_categorical])\n",
    "\n",
    "# Camada Densa final\n",
    "output = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "# Criando o modelo\n",
    "model_lstm = Model(inputs=[numeric_input, categorical_input], outputs=output)\n",
    "\n",
    "# Compilando o modelo\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'precision', 'recall'])\n",
    "\n",
    "# Reshape necessário para a entrada numérica\n",
    "X_train_num = np.expand_dims(X_train_num, axis=-1)\n",
    "X_test_num = np.expand_dims(X_test_num, axis=-1)\n",
    "\n",
    "# Treinamento do modelo\n",
    "model_lstm.fit([X_train_num, X_train_cat], y_train, epochs=50, batch_size=81, validation_split=0.2)\n",
    "\n",
    "# Avaliação do modelo\n",
    "# Avaliação do modelo\n",
    "loss, accuracy, precision, recall = model_lstm.evaluate([X_test_num, X_test_cat], y_test) # Changed model to model_lstm and added precision and recall to unpack the returned values\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Model Accuracy: {accuracy:.2f}')\n",
    "print(f'Model Precision: {precision:.2f}')\n",
    "print(f'Model Recall: {recall:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrvwdbH9jgN4",
    "outputId": "178bddd3-fe4f-4f87-ab9f-f01cf5e616b3"
   },
   "outputs": [],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL3_wANWilga"
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cSOtdfqqiR-e",
    "outputId": "06bdea79-4442-45df-ba82-917d94ba1753"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Definindo os hiperparâmetros para otimização\n",
    "    n_lstm_units = trial.suggest_int('n_lstm_units', 32, 128)\n",
    "    n_dense_units = trial.suggest_int('n_dense_units', 16, 64)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "    epochs = trial.suggest_int('epochs', 10, 100)\n",
    "\n",
    "    # Definindo a entrada da sequência numérica\n",
    "    numeric_input = Input(shape=(X_numeric_seq.shape[1], 1), name='numeric_input')\n",
    "    x_numeric = LSTM(n_lstm_units, return_sequences=False, dropout=dropout_rate)(numeric_input)\n",
    "\n",
    "    # Definindo a entrada da sequência categórica\n",
    "    categorical_input = Input(shape=(X_categorical_seq.shape[1],), name='categorical_input')\n",
    "    x_categorical = Dense(n_dense_units, activation='relu')(categorical_input)\n",
    "\n",
    "    # Concatenando as saídas das camadas numéricas e categóricas\n",
    "    concatenated = Concatenate()([x_numeric, x_categorical])\n",
    "    output = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "    # Criando o modelo\n",
    "    model_lstm = Model(inputs=[numeric_input, categorical_input], outputs=output)\n",
    "\n",
    "    # Compilando o modelo\n",
    "    model_lstm.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Reshape necessário para a entrada numérica\n",
    "    X_numeric_train_reshaped = np.expand_dims(X_train_num, axis=-1)\n",
    "    X_numeric_test_reshaped = np.expand_dims(X_test_num, axis=-1)\n",
    "\n",
    "    # Treinamento do modelo\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Predição e cálculo do recall\n",
    "    y_pred = model_lstm.predict([X_numeric_test_reshaped, X_test_cat])\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "    recall = recall_score(y_test, y_pred_classes)\n",
    "\n",
    "    # Limpando sessão do Keras para evitar sobrecarga de memória\n",
    "    K.clear_session()\n",
    "\n",
    "    return recall\n",
    "\n",
    "# Rodando a otimização\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "# Melhor conjunto de hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros:\", study.best_params)\n",
    "print(\"Melhor recall alcançado:\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "mUhHmPliWe4I"
   ],
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
