{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Atenção**\n",
    "\n",
    "## Para executar esse notebook utilize o T4 GPU\n",
    "\n",
    "Além disso, a saída de algumas células estão comentadas, visto que sua exibição implica na utilização de memória RAM do Colab, gerando erro de processamento. Os códigos estão funcionando, porém precisam de maior capacidade computacional para rodarem sem problemas. Na próxima sprint espera-se conseguir aprimorar as questões de eficiência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrantes\n",
    "\n",
    "- Dayllan Alho\n",
    "- Giovanna Furlan\n",
    "- Luiz Ferreira\n",
    "- Maria Luísa Maia\n",
    "- Thainá Lima\n",
    "- Vinicius Fernandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problema a ser resolvido**\n",
    "\n",
    "O projeto tem como objetivo desenvolver uma aplicação para a Aegea, uma empresa de saneamento, que melhore a detecção de fraudes no consumo de água. Essas fraudes, como a manipulação de hidrômetros e ligações clandestinas, não só prejudicam o faturamento e a qualidade do serviço, mas também podem causar danos à infraestrutura e representar riscos à saúde pública."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Solução Proposta**\n",
    "\n",
    "Para identificar as fraudes, foi proposto o desenvolvimento de uma aplicação baseada em Machine Learning que melhore a capacidade da Aegea de detectar comportamentos fraudulentos no consumo de água. Essa solução considera a influência de variáveis externas, como fatores econômicos, climáticos e geográficos, para aumentar a assertividade na identificação e melhorar os processos de negócio da empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "A configuração de setup é o processo de preparar e organizar o ambiente para uso. Envolvendo a instalação de bibliotecas e configuração de outros ajustes necessários. O objetivo é criar um ambiente funcional para executar tarefas específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação das bibliotecas\n",
    "\n",
    " Nesta seção, são instaladas e importadas as bibliotecas necessárias para a manipulação, análise e visualização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importação da base de dados**\n",
    "\n",
    "Para realizar a análise, padronização e manipulação dos dados é necessário selecionar a base de dados desejada. Neste documento a importação da mesma será feita através do gdown e o arquivo está em formato CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo_base = \"{}.csv\"\n",
    "ids = {\n",
    "    \"CONSUMO_GERAL\": \"1-IOqfwmh_tTIDHeOer8J-HkGFtwuX67g\",\n",
    "    \"FRAUDES\": \"1-MbIlChqQapcxFkoJgpbQIsN9FBLfbX1\",\n",
    "}\n",
    "for key, file_id in ids.items():\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    arquivo_destino = arquivo_base.format(key)\n",
    "    gdown.download(url, arquivo_destino, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAUDES = pd.read_csv(\"./FRAUDES.csv\", delimiter=\",\")\n",
    "CONSUMO_GERAL = pd.read_csv(\"./CONSUMO_GERAL.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot Encoding\n",
    "\n",
    "Uma técnica usada em machine learning para transformar variáveis categóricas em uma forma que os algoritmos possam entender. Cada categoria é convertida em uma coluna binária (0 ou 1), representando a presença ou ausência dessa categoria em uma amostra. É importante porque muitos algoritmos não conseguem trabalhar diretamente com dados categóricos. Ao transformar as categorias em números binários, o modelo pode processar as informações corretamente, melhorando a precisão das previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OHC_trasformation:\n",
    "    ohc_encoders = {}\n",
    "\n",
    "    @classmethod\n",
    "    def encode(cls, df, columns_name):\n",
    "        for column_name in columns_name:\n",
    "            # Instanciando o OneHotEncoder\n",
    "            ohc = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False).set_output(transform=\"pandas\")\n",
    "            # Fit e transformação dos dados\n",
    "            ohc_fit_transform = ohc.fit_transform(df[[column_name]])\n",
    "            # Salvando o encoder para futuras utilizações\n",
    "            cls.ohc_encoders[column_name] = ohc\n",
    "            # Dropando a coluna original\n",
    "            df.drop(columns=[column_name], inplace=True)\n",
    "            # Concatenando o DataFrame original com as colunas One-Hot Encoded\n",
    "            df = pd.concat([df, ohc_fit_transform], axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "# Aplicar o One Hot Encoding no novo ambiente\n",
    "CONSUMO_GERAL = OHC_trasformation.encode(CONSUMO_GERAL, [\"CATEGORIA\", \"TIPO_LIGACAO\"])\n",
    "FRAUDES = OHC_trasformation.encode(FRAUDES, ['STATUS', 'ATRASO'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `TableTransformation` é responsável por transformar um DataFrame usando operações como pivotamento de dados e seleção de colunas estáticas. Isso é útil para reorganizar os dados em formato de tabela e trabalhar com colunas específicas.\n",
    "\n",
    "1. **pivot_data**: Realiza o pivotamento dos dados, utilizando uma chave primária como índice e uma coluna de datas como cabeçalhos. Valores nulos são substituídos por zero.\n",
    "2. **trasform_estatic_data**: Seleciona colunas estáticas, exclui a coluna de valores pivotados, remove duplicatas e ordena pela chave primária.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableTransformation:\n",
    "    def __init__(self, nome_coluna_chave_primaria, nome_coluna_data, nome_coluna_contem_value):\n",
    "        self.nome_coluna_data = nome_coluna_data\n",
    "        self.nome_coluna_chave_primaria = nome_coluna_chave_primaria\n",
    "        self.nome_coluna_contem_value = nome_coluna_contem_value\n",
    "\n",
    "    def pivot_data(self, df):\n",
    "        # Realizando o pivotamento dos dados em Pandas\n",
    "        df_pivot = df.pivot(index=self.nome_coluna_chave_primaria, \n",
    "                            columns=self.nome_coluna_data, \n",
    "                            values=self.nome_coluna_contem_value).fillna(0)\n",
    "        return df_pivot\n",
    "\n",
    "    def trasform_estatic_data(self, df):\n",
    "        # Selecionando as colunas estáticas (incluindo a coluna chave primária)\n",
    "        colunas_estaticas = df.drop(columns=[self.nome_coluna_contem_value]).drop_duplicates()\n",
    "\n",
    "        # Ordenando pelo identificador chave primária (MATRICULA)\n",
    "        colunas_estaticas = colunas_estaticas.sort_values(self.nome_coluna_chave_primaria)\n",
    "\n",
    "        return colunas_estaticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size:1.5em;\">Instanciação da Classe e Execução das Transformações</summary>\n",
    "<br>\n",
    "\n",
    "Neste trecho de código, a classe `TableTransformation` é instanciada e utilizada para realizar transformações em um DataFrame. O processo envolve pivotamento de dados, extração de colunas estáticas, verificação de chaves primárias, e combinação final dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciação da classe e execução das transformações\n",
    "tt = TableTransformation(\"MATRICULA\", \"REFERENCIA\", \"CONS_MEDIDO\")\n",
    "\n",
    "# Realizando o pivotamento no DataFrame CONSUMO_GERAL\n",
    "df_pivot = tt.pivot_data(CONSUMO_GERAL)\n",
    "\n",
    "# Extraindo as colunas estáticas\n",
    "colunas_estaticas = tt.trasform_estatic_data(CONSUMO_GERAL)\n",
    "\n",
    "# Verificando se a chave primária \"MATRICULA\" está presente e se o índice é único\n",
    "if \"MATRICULA\" in colunas_estaticas.columns:\n",
    "    colunas_estaticas.set_index(\"MATRICULA\", inplace=True)\n",
    "\n",
    "# Verificando se os índices de ambos os DataFrames são únicos\n",
    "if not df_pivot.index.is_unique or not colunas_estaticas.index.is_unique:\n",
    "    print(\"Os índices não são únicos. Resetando o índice para evitar conflitos.\")\n",
    "    df_pivot.reset_index(inplace=True)\n",
    "    colunas_estaticas.reset_index(inplace=True)\n",
    "\n",
    "# Concatenando os dados pivotados com as colunas estáticas\n",
    "df_final = pd.concat([df_pivot, colunas_estaticas], axis=1)\n",
    "\n",
    "# Exibindo o resultado final\n",
    "print(\"\\nDataFrame Final (Dados Pivotados + Colunas Estáticas):\")\n",
    "display(df_final.head())\n",
    "\n",
    "# Salvando o DataFrame final em um arquivo CSV\n",
    "df_final.to_csv('resultado_transformacao.csv', index=False)\n",
    "\n",
    "# Mensagem de confirmação\n",
    "print(\"O DataFrame final foi salvo como 'resultado_transformacao.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size:1.5em;\">Transformações sem Normalização</summary>\n",
    "\n",
    "<br>Neste estágio do pipeline de transformação, optamos por não aplicar normalização nos dados. O objetivo é observar como o DataFrame, composto por dados pivotados e colunas estáticas, se comporta diretamente em modelos subsequentes. Ao não normalizar, é possível testar a sensibilidade do modelo a diferentes magnitudes de variáveis, identificando padrões ou problemas específicos de escalas.\n",
    "\n",
    "Este DataFrame foi salvo como `resultado_transformacao.csv` para ser utilizado nas etapas seguintes do projeto.\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
